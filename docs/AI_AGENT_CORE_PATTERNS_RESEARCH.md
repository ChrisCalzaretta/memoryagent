# AI Agent Core Patterns - Deep Research Findings

**Date**: November 26, 2025  
**Focus**: Microsoft Guidance + AI Agent Ecosystem  
**Research Depth**: Comprehensive (15+ sources)  
**Status**: ‚úÖ Research Complete ‚Üí Implementation Ready

---

## üéØ Research Objective

Identify and document the **core patterns that distinguish AI agents from simple LLM integrations**, focusing on Microsoft's ecosystem (Guidance, Semantic Kernel, Azure AI, Agent Framework) and industry-standard patterns.

---

## üìö Research Sources Analyzed

### **Microsoft Official Documentation** (10+ sources)
1. ‚úÖ Azure OpenAI Prompt Engineering Techniques
2. ‚úÖ Microsoft Guidance Library (GitHub)
3. ‚úÖ Semantic Kernel Documentation
4. ‚úÖ Azure AI Foundry Prompt Flow
5. ‚úÖ Microsoft Agent Framework
6. ‚úÖ Azure Content Safety API
7. ‚úÖ Azure AI Search (Vector Search/RAG)
8. ‚úÖ Microsoft Secure Future Initiative (SFI)
9. ‚úÖ Microsoft Cybersecurity Reference Architectures (MCRA)
10. ‚úÖ PromptWizard Research Framework

### **Industry References** (Cross-platform learning)
11. ‚úÖ LangChain Memory Patterns
12. ‚úÖ AutoGen Multi-Agent Patterns
13. ‚úÖ ReAct Pattern (Research Papers)
14. ‚úÖ RAG Best Practices
15. ‚úÖ Token Counting Libraries (tiktoken)

---

## üîç PATTERN CATEGORY 1: Prompt Engineering & Guardrails

### **Critical Discovery**: Microsoft Guidance Library

**What It Is**: Microsoft's library for **structured prompt engineering** with constraints  
**GitHub**: https://github.com/microsoft/guidance  
**Key Features**:
- Handlebars-style templates with {{placeholders}}
- Regex constraints for outputs
- `gen()` and `select()` for controlled generation
- Role-based prompts (system, user, assistant)
- Token-efficient prompt construction

### **Pattern 1.1: ai-system-prompt-definition**

**What to Detect**:
```csharp
// Pattern: Large constant/static strings defining agent behavior
public const string SystemPrompt = "You are a helpful assistant...";
public static string AgentPersona = "Act as an expert in...";

// Pattern: Classes/records storing prompts
public class AgentPolicy {
    public string SystemMessage { get; set; }
    public string[] SafetyGuidelines { get; set; }
}

// Pattern: Configuration files with prompts
"system_prompt": "You are..."
```

**Detection Signals**:
- Constants named: `SystemPrompt`, `AgentPersona`, `AgentPolicy`, `InstructionTemplate`
- Large string literals (>100 chars) containing instruction keywords
- Keywords: "You are", "Act as", "Your role is", "You must", "Never"
- Classes with properties: `SystemMessage`, `Persona`, `Instructions`

**Confidence**: 85-95%

**Best Practice URL**: https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering

---

### **Pattern 1.2: ai-prompt-template**

**What to Detect**:
```csharp
// Pattern: Template engines (Guidance, Handlebars, Semantic Kernel)
var template = "Hello {{user_name}}, your task is {{task_description}}";
var prompt = PromptTemplate.Parse(template);

// Pattern: ChatPromptTemplate (Semantic Kernel)
var chatPrompt = new ChatPromptTemplate(...);
chatPrompt.AddSystemMessage("...");
chatPrompt.AddUserMessage("{{$input}}");

// Pattern: String.Format / interpolation with placeholders
var prompt = $"Context: {context}\nQuestion: {question}";
```

**Detection Signals**:
- Classes: `PromptTemplate`, `ChatPromptTemplate`, `PromptTemplateConfig`
- Methods: `Parse`, `Render`, `AddSystemMessage`, `AddUserMessage`
- Placeholders: `{{variable}}`, `{variable}`, `$variable`, `{$input}`
- Imports: `Microsoft.SemanticKernel.PromptTemplate`, `guidance`

**Confidence**: 90-95%

**Best Practice**: Use template engines for reusable, parameterized prompts

---

### **Pattern 1.3: ai-guardrail-injection**

**What to Detect**:
```csharp
// Pattern: Safety/policy text injection
var safePrompt = prompt + "\n\nSafety Guidelines:\n- No harmful content\n- Respect privacy";

// Pattern: Content moderation API calls
var moderationResult = await contentSafetyClient.AnalyzeText(userInput);
if (moderationResult.IsHarmful) { /* block */ }

// Pattern: Prompt spotlighting (Microsoft technique)
var spotlightedPrompt = $"```user_input\n{userInput}\n```\nAnalyze the above.";

// Pattern: Policy engine integration
var policy = await policyEngine.GetPolicyAsync("agent-behavior");
finalPrompt = policy.Apply(basePrompt);
```

**Detection Signals**:
- Azure Content Safety client usage
- Keywords in prompts: "Safety", "Policy", "Guidelines", "Prohibited", "Must not"
- Presidio PII detection libraries
- Methods: `Moderate`, `CheckCompliance`, `ApplyPolicy`, `SanitizeInput`
- Spotlighting pattern: triple backticks around user input

**Confidence**: 75-90%

**Microsoft Resources**:
- Azure Content Safety: https://learn.microsoft.com/en-us/azure/ai-services/content-safety/
- Spotlighting Technique: https://www.microsoft.com/en-us/security/blog/2024/04/11/how-microsoft-discovers-and-mitigates-evolving-attacks-against-ai-guardrails/

---

## üîç PATTERN CATEGORY 2: Memory & State (Core Agent Behavior)

### **Pattern 2.1: ai-short-term-memory-buffer**

**What to Detect**:
```csharp
// Pattern: Chat history lists
List<ChatMessage> conversationHistory = new();
conversationHistory.Add(new ChatMessage(Role.User, "Hello"));

// Pattern: Message arrays in API calls
var messages = new[] {
    new { role = "system", content = systemPrompt },
    new { role = "user", content = userInput }
};

// Pattern: ConversationBufferMemory (LangChain-style)
public class ConversationBuffer {
    private readonly List<Message> _messages = new();
    public void AddMessage(string role, string content) { }
    public IEnumerable<Message> GetHistory() => _messages;
}

// Pattern: Repeated message passing
foreach (var turn in conversation) {
    var response = await llm.SendAsync(allMessages);
    allMessages.Add(response);
}
```

**Detection Signals**:
- Types: `List<ChatMessage>`, `List<Message>`, `ChatHistory`, `ConversationBuffer`
- Properties/fields: `messages`, `history`, `chatHistory`, `conversationMemory`
- Methods: `AddMessage`, `GetHistory`, `ClearHistory`, `GetLastN`
- Patterns of accumulating messages in loops

**Confidence**: 85-95%

**Key Insight**: Without chat history, it's just a single LLM call, not an agent

---

### **Pattern 2.2: ai-long-term-memory-vector**

**What to Detect**:
```csharp
// Pattern: Vector store usage (Qdrant, Azure AI Search, Pinecone)
var vectorStore = new QdrantMemoryStore(endpoint, apiKey);
await vectorStore.UpsertAsync(collection, embedding, text, metadata);

// Pattern: Azure AI Search vector search
var searchClient = new SearchClient(endpoint, index);
var results = await searchClient.SearchAsync(queryVector, vectorSearch: true);

// Pattern: Semantic Kernel memory connectors
var memory = kernel.GetSemanticTextMemory();
await memory.SaveInformationAsync(collection, text, id);
var recall = await memory.SearchAsync(collection, query, limit: 5);

// Pattern: Embedding generation + storage
var embedding = await embeddingClient.GenerateEmbeddingAsync(text);
await vectorDb.StoreAsync(embedding, metadata);
```

**Detection Signals**:
- Classes: `QdrantClient`, `SearchClient`, `PineconeClient`, `VectorStore`
- Methods: `UpsertAsync`, `SearchAsync`, `SaveInformationAsync`, `GenerateEmbeddingAsync`
- Terms: "vector", "embedding", "semantic", "similarity", "recall"
- Azure AI Search with vector fields
- Qdrant, Pinecone, Weaviate clients

**Confidence**: 90-98%

**Key Insight**: Vector memory = long-term agent memory beyond conversation

---

### **Pattern 2.3: ai-user-profile-memory**

**What to Detect**:
```csharp
// Pattern: User/agent profile storage
public class UserProfile {
    public string UserId { get; set; }
    public Dictionary<string, string> Preferences { get; set; }
    public List<string> ConversationTopics { get; set; }
}

// Pattern: Personalization stores
var profile = await userProfileStore.GetAsync(userId);
var persona = await personaStore.LoadAsync(agentId);

// Pattern: Memory keyed by user/agent
await memoryStore.SaveAsync($"user:{userId}:preferences", data);
await memoryStore.SaveAsync($"agent:{agentId}:persona", persona);
```

**Detection Signals**:
- Classes: `UserProfile`, `AgentPersona`, `MemoryStore`, `PreferenceStore`
- Keys with patterns: `user:*`, `agent:*`, `profile:*`
- Methods: `GetProfile`, `SavePreferences`, `LoadPersona`
- Storage of user-specific or agent-specific data

**Confidence**: 80-90%

---

## üîç PATTERN CATEGORY 3: Tools & Function Calling

### **Pattern 3.1: ai-tool-registration**

**What to Detect**:
```csharp
// Pattern: Semantic Kernel function registration
[KernelFunction, Description("Gets the current weather")]
public async Task<string> GetWeather(string location) { }

kernel.ImportPluginFromType<WeatherPlugin>();

// Pattern: Tool/function collections
var tools = new List<FunctionDef> {
    new FunctionDef {
        Name = "get_weather",
        Description = "Gets current weather",
        Parameters = new { location = "string" }
    }
};

// Pattern: ITool interface implementations
public class CalculatorTool : ITool {
    public string Name => "calculator";
    public Task<string> ExecuteAsync(string input) { }
}

// Pattern: ToolRegistry/ToolManifest
var registry = new ToolRegistry();
registry.Register("weather", new WeatherTool());
```

**Detection Signals**:
- Attributes: `[KernelFunction]`, `[Description]`
- Interfaces: `ITool`, `IPlugin`, `IFunction`
- Classes: `FunctionDef`, `ToolManifest`, `ToolRegistry`, `PluginCollection`
- Methods: `ImportPlugin`, `RegisterTool`, `AddFunction`
- Collections of tool/function definitions

**Confidence**: 90-98%

---

### **Pattern 3.2: ai-tool-routing**

**What to Detect**:
```csharp
// Pattern: LLM output inspection + tool dispatch
var response = await llm.GetCompletionAsync(prompt);
if (response.FunctionCall != null) {
    var result = await ExecuteToolAsync(response.FunctionCall.Name, response.FunctionCall.Arguments);
}

// Pattern: ReAct-style tool loops
while (!isDone) {
    var thought = await llm.ThinkAsync();
    if (thought.Action != null) {
        var observation = await tools[thought.Action].ExecuteAsync(thought.ActionInput);
    }
}

// Pattern: Tool call detection in streaming
await foreach (var update in llm.StreamAsync(messages)) {
    if (update.Type == "function_call") {
        var toolResult = await dispatcher.InvokeAsync(update.FunctionName, update.Arguments);
    }
}
```

**Detection Signals**:
- Conditional tool execution based on LLM output
- Properties: `FunctionCall`, `ToolCalls`, `Action`, `ActionInput`
- Loops that inspect responses and dispatch to tools
- Keywords: "function_call", "tool_use", "action", "routing"

**Confidence**: 85-92%

---

### **Pattern 3.3: ai-external-service-tool**

**What to Detect**:
```csharp
// Pattern: Tools that call external APIs
public class WeatherTool : ITool {
    private readonly HttpClient _http;
    public async Task<string> ExecuteAsync(string location) {
        return await _http.GetStringAsync($"https://api.weather.com?location={location}");
    }
}

// Pattern: Database access tools
public class SqlQueryTool {
    [KernelFunction]
    public async Task<DataTable> QueryDatabase(string sql) {
        using var conn = new SqlConnection(connString);
        // Execute query
    }
}

// Pattern: File system tools
public class FileReadTool {
    public async Task<string> ReadFile(string path) {
        return await File.ReadAllTextAsync(path);
    }
}
```

**Detection Signals**:
- Tool classes with: `HttpClient`, `SqlConnection`, `File` operations
- External API calls within tool methods
- Database queries in tools
- File system operations

**Confidence**: 88-95%

**Key Insight**: External tools = agent has "capabilities" beyond just text generation

---

## üîç PATTERN CATEGORY 4: Planning, Autonomy & Loops

### **Pattern 4.1: ai-task-planner**

**What to Detect**:
```csharp
// Pattern: Plan/Step structures
public class Plan {
    public List<Step> Steps { get; set; }
}

public class Step {
    public string Description { get; set; }
    public string ToolName { get; set; }
}

// Pattern: Semantic Kernel Planner (deprecated but still used)
var planner = new FunctionCallingStepwisePlanner();
var plan = await planner.CreatePlanAsync(kernel, goal);

// Pattern: LLM-generated plans
var planningPrompt = "Break down this task into steps: {task}";
var planJson = await llm.GetCompletionAsync(planningPrompt);
var plan = JsonSerializer.Deserialize<Plan>(planJson);
```

**Detection Signals**:
- Classes: `Plan`, `Planner`, `Step`, `TaskList`, `Subtask`
- Methods: `CreatePlan`, `DecomposeTasks`, `GeneratePlan`
- Semantic Kernel Planner usage (even if deprecated)
- JSON structures with "steps", "tasks", "plan"

**Confidence**: 85-95%

---

### **Pattern 4.2: ai-action-loop (ReAct)**

**What to Detect**:
```csharp
// Pattern: ReAct loop (Reason ‚Üí Act ‚Üí Observe)
while (!goalAchieved && iterations < maxIterations) {
    // Think/Reason
    var thought = await llm.ThinkAsync(context);
    
    // Act
    if (thought.RequiresAction) {
        var actionResult = await ExecuteActionAsync(thought.Action);
        
        // Observe
        context.AddObservation(actionResult);
    }
    
    goalAchieved = thought.IsFinalAnswer;
}

// Pattern: Agent executor loops
var agent = new AgentExecutor(llm, tools);
var result = await agent.RunAsync(goal, maxIterations: 10);

// Pattern: Iterative refinement
do {
    var response = await llm.GetCompletionAsync(prompt);
    if (NeedsMoreWork(response)) {
        prompt = RefinePrompt(response);
    } else {
        break;
    }
} while (true);
```

**Detection Signals**:
- While/do loops with LLM calls inside
- Keywords: "ReAct", "think", "act", "observe", "iteration", "refinement"
- Conditional action execution based on LLM outputs
- Loop termination based on LLM decision (e.g., `isFinalAnswer`)

**Confidence**: 80-90%

**Key Insight**: Loops = autonomy. Single call = not autonomous.

---

### **Pattern 4.3: ai-multi-agent-orchestrator**

**What to Detect**:
```csharp
// Pattern: Multiple agent roles
var planner = new PlannerAgent(llm);
var executor = new ExecutorAgent(llm, tools);
var critic = new CriticAgent(llm);

var plan = await planner.CreatePlanAsync(task);
var result = await executor.ExecuteAsync(plan);
var feedback = await critic.ReviewAsync(result);

// Pattern: AutoGen-style conversable agents
var agents = new[] {
    new ConversableAgent("Planner"),
    new ConversableAgent("Executor"),
    new ConversableAgent("Critic")
};
await agents.InitiateConversationAsync(task);

// Pattern: Agent manager/orchestrator
public class AgentOrchestrator {
    private readonly Dictionary<string, IAgent> _agents;
    
    public async Task<string> RouteToAgent(string task, string agentType) {
        return await _agents[agentType].ExecuteAsync(task);
    }
}
```

**Detection Signals**:
- Multiple agent instances with different roles/names
- Classes: `AgentOrchestrator`, `AgentManager`, `MultiAgentSystem`
- Role names: "Planner", "Executor", "Critic", "Reviewer", "Manager"
- Agent-to-agent communication patterns

**Confidence**: 85-95%

---

### **Pattern 4.4: ai-self-reflection**

**What to Detect**:
```csharp
// Pattern: Self-critique/review
var output = await agent.GenerateAsync(task);
var critique = await agent.CritiqueAsync(output);
if (!critique.IsGood) {
    output = await agent.ImproveAsync(output, critique.Feedback);
}

// Pattern: Critic agent reviewing another agent
var executorOutput = await executor.ExecuteAsync(task);
var review = await critic.ReviewAsync(executorOutput);

// Pattern: Reflection prompts
var reflectionPrompt = $"Review your previous answer: {answer}\nWhat could be improved?";
var reflection = await llm.GetCompletionAsync(reflectionPrompt);
```

**Detection Signals**:
- Methods: `Critique`, `Review`, `Reflect`, `Improve`, `SelfEvaluate`
- Two-step patterns: generate ‚Üí critique ‚Üí regenerate
- Prompts containing: "review", "critique", "improve", "what's wrong"
- Critic/reviewer agent roles

**Confidence**: 75-88%

---

## üîç PATTERN CATEGORY 5: RAG & Knowledge Integration

### **Pattern 5.1: ai-embedding-generation**

**What to Detect**:
```csharp
// Pattern: Azure OpenAI embedding calls
var embeddingClient = new AzureOpenAIClient(endpoint, credential);
var embedding = await embeddingClient.GetEmbeddingsAsync("text-embedding-ada-002", text);

// Pattern: Semantic Kernel text embedding
var textEmbedding = kernel.GetTextEmbeddingGeneration();
var vector = await textEmbedding.GenerateEmbeddingAsync(text);

// Pattern: Batch embedding generation
var texts = new[] { "doc1", "doc2", "doc3" };
var embeddings = await embeddingClient.GenerateEmbeddingsAsync(texts);
foreach (var (text, emb) in texts.Zip(embeddings)) {
    await vectorStore.UpsertAsync(emb, text);
}
```

**Detection Signals**:
- Methods: `GenerateEmbedding`, `GetEmbeddings`, `Embed`
- Model names: "text-embedding-ada-002", "text-embedding-3-large"
- Client types: `EmbeddingClient`, `TextEmbeddingGeneration`
- Vector arrays (float[]) being generated from text

**Confidence**: 92-98%

---

### **Pattern 5.2: ai-vector-search-rag**

**What to Detect**:
```csharp
// Pattern: Retrieve ‚Üí Augment ‚Üí Generate
var queryEmbedding = await embeddingClient.GenerateEmbeddingAsync(query);
var relevantDocs = await vectorStore.SearchAsync(queryEmbedding, topK: 5);

var context = string.Join("\n", relevantDocs.Select(d => d.Content));
var augmentedPrompt = $"Context:\n{context}\n\nQuestion: {query}\nAnswer:";

var answer = await llm.GetCompletionAsync(augmentedPrompt);

// Pattern: Semantic Kernel memory search
var recall = await memory.SearchAsync("facts", query, limit: 3);
var contextStr = string.Join("\n", recall.Select(r => r.Text));
```

**Detection Signals**:
- Three-step pattern: embedding ‚Üí search ‚Üí prompt augmentation
- Methods: `SearchAsync`, `SearchSimilar`, `GetRelevantDocuments`
- Context injection into prompts
- String joining of search results

**Confidence**: 88-95%

**Key Insight**: RAG = agent with knowledge beyond training data

---

### **Pattern 5.3: ai-rag-orchestrator**

**What to Detect**:
```csharp
// Pattern: Conditional RAG
public async Task<string> AnswerWithRAG(string query) {
    if (RequiresKnowledge(query)) {
        var context = await RetrieveContext(query);
        return await GenerateWithContext(query, context);
    } else {
        return await GenerateDirectly(query);
    }
}

// Pattern: Multi-step RAG
var initialDocs = await VectorSearch(query);
var rerankedDocs = await Rerank(initialDocs, query);
var finalContext = ExtractRelevant(rerankedDocs);
var answer = await Generate(query, finalContext);

// Pattern: Hybrid search (vector + keyword)
var vectorResults = await vectorSearch.SearchAsync(embedding);
var keywordResults = await fullTextSearch.SearchAsync(keywords);
var merged = MergeResults(vectorResults, keywordResults);
```

**Detection Signals**:
- Conditional retrieval logic
- Multi-step retrieval (search ‚Üí rerank ‚Üí extract)
- Hybrid search combining vector and keyword
- Methods: `RequiresKnowledge`, `ShouldRetrieve`, `Rerank`

**Confidence**: 82-92%

---

## üîç PATTERN CATEGORY 6: Safety & Governance

### **Pattern 6.1: ai-content-moderation**

**What to Detect**:
```csharp
// Pattern: Azure Content Safety
var contentSafetyClient = new ContentSafetyClient(endpoint, credential);
var result = await contentSafetyClient.AnalyzeTextAsync(userInput);

if (result.HateResult.Severity > 2 || result.ViolenceResult.Severity > 2) {
    return "Content blocked due to policy violation";
}

// Pattern: Pre/post LLM moderation
var preModeration = await Moderate(userInput);
if (preModeration.IsBlocked) return "Blocked";

var response = await llm.GetCompletionAsync(userInput);

var postModeration = await Moderate(response);
if (postModeration.IsBlocked) return "Response blocked";
```

**Detection Signals**:
- Classes: `ContentSafetyClient`, `ModerationClient`
- Methods: `Analyze`, `Moderate`, `CheckCompliance`
- Azure Content Safety imports
- Severity/threshold checks
- Pre and post-LLM moderation

**Confidence**: 90-95%

**Microsoft Resource**: https://learn.microsoft.com/en-us/azure/ai-services/content-safety/

---

### **Pattern 6.2: ai-pii-scrubber**

**What to Detect**:
```csharp
// Pattern: Presidio (Microsoft PII library)
var analyzer = new AnalyzerEngine();
var results = analyzer.AnalyzeAsync(text, language: "en");
var anonymized = Anonymize(text, results);

// Pattern: Regex-based scrubbing
var emailPattern = @"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b";
var scrubbed = Regex.Replace(text, emailPattern, "[EMAIL]");

var ssnPattern = @"\b\d{3}-\d{2}-\d{4}\b";
scrubbed = Regex.Replace(scrubbed, ssnPattern, "[SSN]");

// Pattern: Azure AI Language PII detection
var languageClient = new TextAnalyticsClient(endpoint, credential);
var piiResult = await languageClient.RecognizePiiEntitiesAsync(text);
var redacted = RedactPII(text, piiResult.Entities);
```

**Detection Signals**:
- Libraries: Presidio, Azure AI Language
- Methods: `RecognizePii`, `Anonymize`, `Redact`, `Scrub`, `Mask`
- Regex patterns for emails, SSNs, phone numbers
- Entity recognition for PII
- Replacement with placeholders: `[EMAIL]`, `[SSN]`, `[REDACTED]`

**Confidence**: 85-92%

**Microsoft Resource**: Presidio GitHub

---

### **Pattern 6.3: ai-tenant-data-boundary**

**What to Detect**:
```csharp
// Pattern: Tenant-scoped vector stores
var collection = $"tenant_{tenantId}_knowledge";
await vectorStore.CreateCollectionAsync(collection);

// Pattern: Row-level security in queries
var query = $"SELECT * FROM documents WHERE tenant_id = @tenantId";

// Pattern: Tenant isolation enforcement
public class TenantIsolatedMemoryStore {
    private readonly string _tenantId;
    
    public async Task SaveAsync(string key, string value) {
        var scopedKey = $"{_tenantId}:{key}";
        await _store.SaveAsync(scopedKey, value);
    }
}

// Pattern: Tenant filtering in searches
var results = await search.SearchAsync(query, filter: $"tenant_id eq '{tenantId}'");
```

**Detection Signals**:
- Tenant ID in collection/index/table names
- Filtering by tenant_id in queries
- Tenant-scoped keys/namespaces
- Row-level security patterns
- Multi-tenant isolation enforcement

**Confidence**: 80-90%

---

### **Pattern 6.4: ai-token-budget-enforcement**

**What to Detect**:
```csharp
// Pattern: Token counting
using TiktokenSharp; // or Microsoft.Extensions.AI.Tokenizer
var tokenizer = TiktokenSharp.Tiktoken.EncodingForModel("gpt-4");
var tokens = tokenizer.Encode(text);

if (tokens.Count > maxTokens) {
    throw new Exception("Token limit exceeded");
}

// Pattern: Budget enforcement
var usage = await GetUsageForUser(userId);
if (usage.TotalTokens > userBudget) {
    throw new BudgetExceededException();
}

// Pattern: Cost tracking
var cost = tokens.Count * costPerToken;
await billingService.RecordUsageAsync(userId, tokens.Count, cost);
```

**Detection Signals**:
- Libraries: tiktoken, TiktokenSharp, tokenizer
- Methods: `Encode`, `CountTokens`, `EstimateCost`
- Budget/quota checks
- Token limits: `max_tokens`, `token_limit`, `budget`
- Cost calculation: `tokens * price`

**Confidence**: 85-92%

---

### **Pattern 6.5: ai-prompt-logging-with-redaction**

**What to Detect**:
```csharp
// Pattern: Redacted logging
var redactedPrompt = RedactPII(prompt);
_logger.LogInformation("Prompt sent: {Prompt}", redactedPrompt);

var redactedResponse = RedactPII(response);
_logger.LogInformation("Response received: {Response}", redactedResponse);

// Pattern: Audit logging with sanitization
await auditLog.LogPromptAsync(new PromptAuditEntry {
    UserId = userId,
    Prompt = Sanitize(prompt),
    Response = Sanitize(response),
    Timestamp = DateTime.UtcNow
});

// Pattern: Structured logging with fields
_logger.LogInformation(
    "LLM call: UserId={UserId}, Model={Model}, Tokens={Tokens}, Prompt={Prompt}",
    userId, model, tokenCount, RedactedPrompt(prompt)
);
```

**Detection Signals**:
- Methods: `Redact`, `Sanitize`, `Mask` applied to logs
- Logging of prompts AND responses
- Audit trail creation
- PII removal before logging

**Confidence**: 75-88%

---

## üîç PATTERN CATEGORY 7: FinOps / Cost Control

### **Pattern 7.1: ai-token-metering**

**What to Detect**:
```csharp
// Pattern: Token usage tracking
var startTokens = usage.TotalTokens;
var response = await llm.GetCompletionAsync(prompt);
var endTokens = response.Usage.TotalTokens;
var tokensUsed = endTokens - startTokens;

await meteringService.RecordAsync(userId, tokensUsed, model);

// Pattern: Usage aggregation
public class UsageMetrics {
    public int PromptTokens { get; set; }
    public int CompletionTokens { get; set; }
    public int TotalTokens { get; set; }
    public decimal Cost { get; set; }
}

await metricsStore.IncrementAsync($"user:{userId}:tokens", tokensUsed);
```

**Detection Signals**:
- Properties: `Usage.TotalTokens`, `PromptTokens`, `CompletionTokens`
- Methods: `RecordUsage`, `IncrementMetrics`, `TrackTokens`
- Aggregation by user, project, agent
- Token delta calculations

**Confidence**: 88-95%

---

### **Pattern 7.2: ai-cost-budget-guardrail**

**What to Detect**:
```csharp
// Pattern: Hard budget check
var currentCost = await GetMonthlySpendAsync(userId);
if (currentCost + estimatedCost > monthlyBudget) {
    throw new BudgetExceededException("Monthly budget exceeded");
}

// Pattern: Soft budget with alerts
if (currentCost > monthlyBudget * 0.8) {
    await alertService.SendAlertAsync(userId, "Approaching budget limit");
}

// Pattern: Auto-disable on budget
if (currentCost >= monthlyBudget) {
    await agentService.DisableAsync(agentId);
    _logger.LogWarning("Agent {AgentId} disabled due to budget", agentId);
}
```

**Detection Signals**:
- Budget comparisons and enforcement
- Methods: `CheckBudget`, `EnforceBudget`, `DisableOnBudget`
- Alerting on thresholds (80%, 90%, 100%)
- Auto-disable logic

**Confidence**: 82-90%

---

## üéØ The "IS THIS AN AGENT?" Algorithm

Based on research, here's the **minimum pattern set** to confidently identify an AI agent:

```
IS_AGENT = RequireAll(
    [1] LLM Client Pattern
        (OpenAIClient, ChatCompletion, etc.)
    
    AND
    
    [2] Prompt Pattern
        (SystemPrompt, PromptTemplate, or Guardrail)
    
    AND
    
    [3] At Least ONE of:
        - Memory (short-term buffer OR vector store)
        - Tools (tool registration OR routing)
    
    AND
    
    [4] OPTIONAL (increases confidence):
        - Action Loop (ReAct, planning)
        - Multi-step reasoning
        - RAG pipeline
)

CONFIDENCE:
- Has [1] + [2] + [3]: 75% (basic agent)
- Has [1] + [2] + [3] + loop: 90% (autonomous agent)
- Has [1] + [2] + [3] + loop + safety: 95% (production agent)
```

---

## üìä Pattern Summary

| Category | Patterns | Confidence Range | Detection Method |
|----------|----------|------------------|------------------|
| **Prompt Engineering** | 3 | 75-95% | String analysis, class detection |
| **Memory & State** | 3 | 80-95% | Type detection, collection patterns |
| **Tools & Functions** | 3 | 85-98% | Attribute, interface detection |
| **Planning & Loops** | 4 | 75-95% | Control flow analysis |
| **RAG & Knowledge** | 3 | 82-98% | Embedding, search patterns |
| **Safety & Governance** | 5 | 75-95% | API usage, filtering logic |
| **FinOps & Cost** | 2 | 82-95% | Metering, budget checks |
| **TOTAL** | **23 Patterns** | **75-98%** | Multi-method detection |

---

## üöÄ Implementation Strategy

### **Phase 1: Core Agent Detection** (PRIORITY)
```
1. ai-system-prompt-definition
2. ai-prompt-template
3. ai-short-term-memory-buffer
4. ai-long-term-memory-vector
5. ai-tool-registration
6. ai-action-loop
7. ai-vector-search-rag

Total: 7 patterns
Effort: ~4 hours
Impact: Can now identify agents vs LLM calls
```

### **Phase 2: Production Readiness**
```
8. ai-content-moderation
9. ai-pii-scrubber
10. ai-token-budget-enforcement
11. ai-guardrail-injection
12. ai-token-metering

Total: 5 patterns
Effort: ~2 hours
Impact: Can assess production safety
```

### **Phase 3: Advanced Capabilities**
```
13. ai-task-planner
14. ai-multi-agent-orchestrator
15. ai-self-reflection
16. ai-rag-orchestrator
17-23. Remaining patterns

Total: 11 patterns
Effort: ~3 hours
Impact: Complete coverage
```

---

## ‚úÖ Next Steps

1. ‚úÖ Research Complete
2. ‚è≠Ô∏è Create `AIAgentPatternDetector.cs`
3. ‚è≠Ô∏è Implement 23 detection methods
4. ‚è≠Ô∏è Add 23 best practices to catalog
5. ‚è≠Ô∏è Build and test
6. ‚è≠Ô∏è Document implementation

**Status**: Ready to implement! üöÄ

---

**Research Conducted By**: AI Assistant (Claude)  
**Completion Date**: November 26, 2025  
**Sources**: 15+ Microsoft + industry references  
**Total Patterns Identified**: 23  
**Next Action**: Begin implementation

